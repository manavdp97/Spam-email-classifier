# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XIxOqbNNgOM-D8pQnAgLfw0bZrkdyvZT
"""

import sys
import tensorflow as tf
from tensorflow.contrib.layers import flatten

import numpy as np
from sklearn.utils import shuffle


# Returns a conv2d layer with kernel of size: shape and a specified input
def conv2d(input, shape):
    conv = tf.Variable(tf.truncated_normal(shape=shape, mean=0, stddev=0.1))
    bias = tf.Variable(tf.zeros(shape[-1]))
    conv = tf.nn.conv2d(input, conv, strides=[1, 1, 1, 1], padding='VALID') + bias
    return conv

# Returns a fully connected layer of a specified shape and a specified input
def linear(input, shape):
    fc = tf.Variable(tf.truncated_normal(shape=shape, mean=0, stddev=0.1))
    bias = tf.Variable(tf.zeros(shape[-1]))
    fc = tf.matmul(input, fc) + bias
    return fc

# Returns a computational graph for LeNet 5 architecture
def LeNet(images):
    # Conv 1
    conv1 = tf.nn.relu(conv2d(input=images, shape=(5, 5, 1, 6)))

    # Pool 1
    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')

    # Conv 2
    conv2 = tf.nn.relu(conv2d(input=conv1, shape=(5, 5, 6, 16)))

    # Pool 2
    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')

    # Flatten
    fc0 = flatten(conv2)

    # Full 1
    fc1 = tf.nn.relu(linear(input=fc0, shape=(400, 120)))

    # Full 2
    fc2 = tf.nn.relu(linear(input=fc1, shape=(120, 84)))

    # Out
    output = linear(input=fc2, shape=(84, 10))

    return output
  
  
# Read and prepare MNIST
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# Pad and reshape training and testing data
paddings = [[0, 0], [2, 2], [2, 2]]
x_train, x_test = np.pad(x_train, paddings, mode='constant'), np.pad(x_test, paddings, mode='constant')
x_train, x_test = np.expand_dims(x_train, axis=3), np.expand_dims(x_test, axis=3)

# Define all parameters/hyperparameters
EPOCHS = 1  # int(sys.argv[1])
BATCH_SIZE = 128
rate = 0.001

# Define placeholders for Tf computational graph
x = tf.placeholder(tf.float32, (None, 32, 32, 1))
y = tf.placeholder(tf.int32, (None))

# Convert y labels to one hot encoding
one_hot_y = tf.one_hot(y, 10)

# Setup softmax, loss function and optimizer
logits = LeNet(x)
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)
loss_operation = tf.reduce_mean(cross_entropy)
optimizer = tf.train.AdamOptimizer(learning_rate=rate)
training_operation = optimizer.minimize(loss_operation)

# Start a new tf session
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    num_examples = x_train.shape[0]
    
    # Training LeNet on training set using mini-batches
    print("Training...")
    print()
    for i in range(EPOCHS):
        x_train, y_train = shuffle(x_train, y_train)
        for offset in range(0, num_examples, BATCH_SIZE):
            end = offset + BATCH_SIZE
            batch_x, batch_y = x_train[offset:end], y_train[offset:end]
            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})

    # Setup accuracy metric
    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))
    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    
    # Testing accuracy after completing training
    accuracy = sess.run(accuracy_operation, feed_dict={x: x_test, y: y_test})
    print(f"Trained for {EPOCHS} EPOCHS")
    print(f"Final Test Accuracy is {accuracy*100:.2f}%")
